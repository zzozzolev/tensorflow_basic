{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작성자 : 노혜미 박승리 (YBIGTA 10기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (번외 1-1) Tensorflow를 활용한 Multi-Variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time # 계산시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.] # float형태를 위해, 소수점을 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random_normal([1]), name = 'weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name = 'weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name = 'weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = w1 * x1 + w2 * x2 + w3 * x3 + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost는 우리가 세운 가설(y 추정치)에서 실제 Y값을 뺀 것에 제곱을 한 뒤, 각각을 모두 더하고 이에 대한 평균을 내겠다는 것이다.\n",
    "\n",
    "우리가 세운 가설이 실제 Y값과 비슷하다면 제곱되는 수의 크기가 작으므로 cost는 작아질 것이고 반대라면 cost가 커질 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize function\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행시키기 전에 반드시 tf.global_variables_initializer()로 초기화를 해줘야 에러가 나지 않는다.\n",
    "\n",
    "with tf.Session() as sess과 같이 쓴 이유는 session은 열고 닫는 과정을 거쳐야 되는데 저렇게 쓰게 되면 일일이 세션을 열고 닫지 않아도 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑에서 '_'과 뭔지 궁금할 수 있을 것이다.\n",
    "\n",
    "_에 해당하는 것은 train이다. train의 값은 run을 해줘야 하지만 우리가 나중에 print를 한다든지 쓸 값이 아니다.\n",
    "\n",
    "그래서 한꺼번에 run 해줄 때,cost와 hypothesis는 쓰지만 train은 쓰지 않으므로 '_'를 쓴 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 40421.7 \n",
      "predicted Y:\n",
      " [-24.11546707 -31.62531281 -29.64182472 -33.68144608 -23.71737099]\n",
      "step: 5000 cost: 0.421932 \n",
      "predicted Y:\n",
      " [ 152.31440735  184.11781311  181.01208496  195.97280884  141.54447937]\n",
      "step: 10000 cost: 0.211829 \n",
      "predicted Y:\n",
      " [ 151.79940796  184.46759033  180.84992981  195.88818359  141.97621155]\n",
      "step: 15000 cost: 0.194538 \n",
      "predicted Y:\n",
      " [ 151.65719604  184.56214905  180.80245972  195.88285828  142.07614136]\n",
      "step: 20000 cost: 0.190783 \n",
      "predicted Y:\n",
      " [ 151.61230469  184.59034729  180.78523254  195.89613342  142.09172058]\n",
      "13.94911527633667\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    for step in range(20001):\n",
    "        cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    \n",
    "        if step % 5000 == 0:\n",
    "            print('step:', step, 'cost:', cost_val, '\\npredicted Y:\\n', hy_val) \n",
    "    t2 = time.time()\n",
    "    print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-e108970238bc>\", line 1, in <module>\n    x1 = tf.placeholder(tf.float32)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-99aad76c4c95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w1:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w2:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w3:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cost:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-e108970238bc>\", line 1, in <module>\n    x1 = tf.placeholder(tf.float32)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\PARK SEONGRI\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print('step:', step, 'w1:', sess.run(w1), 'w2:', sess.run(w2), 'w3:', sess.run(w3), 'b:', sess.run(b), 'cost:', sess.run(cost)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1. 왜 바로 위의 코드처럼 선형회귀 때 같이 train만 세션을 실행한다면 오류가 생기는 것일까? \n",
    "- Q2. 왜 x1과 x1_data를 구분하여 feed 시키는 형태로 식을 짠 것일까? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (번외 1-2) Tensorflow를 활용한 Multi-Variable linear regression(Matrix 계산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]] # rank2, 5X3 matrix\n",
    "y_data = [[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]] # rank2, 5X1 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 3]) # None : n개, 여기서는 5개\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3,1]), name = 'weight') # 3은 input의 개수, 1은 output의 개수\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias') # bias의 output개수는 Y의 output의 개수와 같아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 178397.0 \n",
      "predicted Y:\n",
      " [[-217.4924469 ]\n",
      " [-269.71856689]\n",
      " [-261.45748901]\n",
      " [-286.00027466]\n",
      " [-206.5461731 ]]\n",
      "step: 5000 cost: 1.17618 \n",
      "predicted Y:\n",
      " [[ 153.06187439]\n",
      " [ 183.58607483]\n",
      " [ 181.06736755]\n",
      " [ 196.37693787]\n",
      " [ 140.78640747]]\n",
      "step: 10000 cost: 0.213609 \n",
      "predicted Y:\n",
      " [[ 151.97612   ]\n",
      " [ 184.32965088]\n",
      " [ 180.73358154]\n",
      " [ 196.14303589]\n",
      " [ 141.75605774]]\n",
      "step: 15000 cost: 0.149349 \n",
      "predicted Y:\n",
      " [[ 151.69386292]\n",
      " [ 184.52246094]\n",
      " [ 180.64611816]\n",
      " [ 196.08659363]\n",
      " [ 142.00354004]]\n",
      "step: 20000 cost: 0.144908 \n",
      "predicted Y:\n",
      " [[ 151.61914062]\n",
      " [ 184.57307434]\n",
      " [ 180.62232971]\n",
      " [ 196.07546997]\n",
      " [ 142.06503296]]\n",
      "10.901878833770752\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    t1 = time.time()\n",
    "    \n",
    "    for step in range(20001):\n",
    "        cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict = {X : x_data, Y : y_data})\n",
    "        if step % 5000 == 0:\n",
    "            print('step:', step, 'cost:', cost_val, '\\npredicted Y:\\n', hy_val )\n",
    "            \n",
    "    t2 = time.time()\n",
    "    print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix계산 시간이 조금 더 적게 걸렸다.\n",
    "\n",
    "더 많은 데이터일 경우 확연하게 차이가 날 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (번외 1-3) Tensorflow를 활용한 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logistic regression은 input이 들어왔을 때, 결과가 0이냐 1이냐를 판단하는 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]] # 0 or 1 binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이쯤에서 의문이 드는 게 placeholder와 Variable의 차이일 것이다.\n",
    "\n",
    "두 개 모두 변수를 담는 그릇이지만 조금 다르다.\n",
    "\n",
    "placeholder에는 실제 training data를 넣는다. \n",
    "\n",
    "Variable에는 weight와 bias를 넣는다.\n",
    "\n",
    "즉, placeholder에는 update가 필요없는 data가 들어가는 것이고 variable에는 update가 필요한 data가 들어가는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
    "# tf.div(1., 1. + tf.exp(tf.matmul(X,W) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost 함수가 이렇게 되는 이유는 그래프를 통해 살펴보는 것이 이해가 더 쉬울 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cost](http://adit.io/imgs/logistic/log_graph.png)\n",
    "이미지 출처: http://adit.io/posts/2016-03-13-Logistic-Regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왼쪽 그래프 y = -logx , 오른쪽 그래프 y = -log(1-x)\n",
    "\n",
    "여기서 x는 예측 값(hypothesis)가 되고, y는 실제 값(Y)가 된다. (your prediction에서 100%에 해당하는 x 값이 1이다.)\n",
    "\n",
    "만약 실제 값이 1인데, 예측값을 0이라고 했다면 우리는 cost를 쎄게 줘서 모델에게 잘못 예측을 했다는 것을 알려야 된다.\n",
    "\n",
    "반대로 실제 값이 1일 때, 예측값을 1이라고 했다면 모델이 정확한 것이므로 cost를 줄 필요가 없다. (cost를 모델에게 주는 벌(?)로 이해하면 되겠다.)\n",
    "\n",
    "위의 그래프는 이러한 상황을 그대로 반영했다.\n",
    "\n",
    "실제 값이 1일 때, 예측 값이 0에 가까우면 cost가 발산하고 1에 가까우면 cost는 거의 0에 수렴한다.\n",
    "\n",
    "실제 값이 0일 때는 정 반대이다.\n",
    "\n",
    "cost함수에서 log함수 앞에 Y를 붙인 이유는 Y가 1일때는 왼쪽 그래프만 고려하면 되고, Y가 0일때는 오른쪽 그래프만 고려하면 되기 때문이다.\n",
    "\n",
    "Y=0일때 왼쪽 함수 값은 0이 곱해지기 때문에 없어지고 Y=1일때는 오른쪽 함수 값이 없어진다.\n",
    "\n",
    "(밑의 cost 함수를 보면 -log가 아닌데 맨 앞으로 -를 빼냈다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-03)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hypothesis > 0.5이면 T, < 0.5이면 F이고 이를 float32 dtype으로 바꾸면 1, 0이 된다.\n",
    "# 보통 1을 True로, 0을 False로 생각한다. 그래서 이의 중간 값이 0.5를 기준으로 한 것이다.\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "\n",
    "# predicted == Y 이면 T, 아니면 F이고 이를 1, 0으로 바꾼다.\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 1.39176 \n",
      "predicted Y:\n",
      " [[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "\n",
      "step: 5000 cost: 0.621105 \n",
      "predicted Y:\n",
      " [[ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "\n",
      "step: 10000 cost: 0.542751 \n",
      "predicted Y:\n",
      " [[ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "\n",
      "step: 15000 cost: 0.491557 \n",
      "predicted Y:\n",
      " [[ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "\n",
      "step: 20000 cost: 0.448958 \n",
      "predicted Y:\n",
      " [[ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "\n",
      "Accuracy: 0.833333\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(20001):\n",
    "        cost_val, pre, _ = sess.run([cost, predicted, train], feed_dict = {X : x_data, Y : y_data})\n",
    "        if step % 5000 == 0:\n",
    "            print('step:', step, \"cost:\", cost_val, \"\\npredicted Y:\\n\", pre)\n",
    "            print()\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict = {X : x_data, Y : y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (번외 2) Optimizer 성능비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 multivariable linear regression과 optimizer만 다르다. \n",
    "- 시작 지점이 모두 같기 때문에, step 0에서의 cost값이 모두 같다.\n",
    "- 최적의 결과를 위해 각 optimizer 별로 learing rate를 다르게 줬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵티마이저에 대해 알고 싶다면 다음의 링크를 참고하자.\n",
    "\n",
    "*옵티마이저 안내서*\n",
    "https://github.com/YBIGTA/Deep_learning/blob/master/RNN/nlp/%EC%9D%B4%EB%A1%A0/Tensorflow%20Optimizer%20%EC%95%88%EB%82%B4%EC%84%9C.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multivariable linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientDescent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 68860.0 \n",
      "predicted y:\n",
      " [[ -87.23231506]\n",
      " [ -91.4056015 ]\n",
      " [ -97.27399445]\n",
      " [-102.95302582]\n",
      " [ -68.74664307]]\n",
      "step: 5000 cost: 2.44453 \n",
      "predicted y:\n",
      " [[ 149.21354675]\n",
      " [ 185.96690369]\n",
      " [ 179.59849548]\n",
      " [ 197.8147583 ]\n",
      " [ 141.73757935]]\n",
      "step: 10000 cost: 1.44062 \n",
      "predicted y:\n",
      " [[ 150.24142456]\n",
      " [ 185.290802  ]\n",
      " [ 179.94970703]\n",
      " [ 197.78677368]\n",
      " [ 141.08848572]]\n",
      "step: 15000 cost: 1.12916 \n",
      "predicted y:\n",
      " [[ 150.58778381]\n",
      " [ 185.07862854]\n",
      " [ 180.08796692]\n",
      " [ 197.63685608]\n",
      " [ 141.02111816]]\n",
      "step: 20000 cost: 0.916443 \n",
      "predicted y:\n",
      " [[ 150.74908447]\n",
      " [ 184.990448  ]\n",
      " [ 180.16583252]\n",
      " [ 197.47177124]\n",
      " [ 141.09240723]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        cost_val, hypo_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%5000 == 0:\n",
    "            print(\"step:\", step, \"cost:\", cost_val, \"\\npredicted y:\\n\", hypo_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본템(?)의 한계인 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 68860.0 \n",
      "predicted y:\n",
      " [[ -87.23231506]\n",
      " [ -91.4056015 ]\n",
      " [ -97.27399445]\n",
      " [-102.95302582]\n",
      " [ -68.74664307]]\n",
      "step: 5000 cost: 0.122591 \n",
      "predicted y:\n",
      " [[ 151.74658203]\n",
      " [ 184.47531128]\n",
      " [ 180.05627441]\n",
      " [ 196.45507812]\n",
      " [ 142.25134277]]\n",
      "step: 10000 cost: 0.106063 \n",
      "predicted y:\n",
      " [[ 151.75942993]\n",
      " [ 184.47709656]\n",
      " [ 180.20199585]\n",
      " [ 196.29104614]\n",
      " [ 142.27111816]]\n",
      "step: 15000 cost: 0.104489 \n",
      "predicted y:\n",
      " [[ 151.74183655]\n",
      " [ 184.48806763]\n",
      " [ 180.25094604]\n",
      " [ 196.25901794]\n",
      " [ 142.25230408]]\n",
      "step: 20000 cost: 0.104351 \n",
      "predicted y:\n",
      " [[ 151.74153137]\n",
      " [ 184.49746704]\n",
      " [ 180.27182007]\n",
      " [ 196.25576782]\n",
      " [ 142.25120544]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        cost_val, hypo_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%5000 == 0:\n",
    "            print(\"step:\", step, \"cost:\", cost_val, \"\\npredicted y:\\n\", hypo_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역시 널리 쓰이는 optimizer답게 가장 많이 cost를 낮추었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=0.1)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 68860.0 \n",
      "predicted y:\n",
      " [[ -87.23231506]\n",
      " [ -91.4056015 ]\n",
      " [ -97.27399445]\n",
      " [-102.95302582]\n",
      " [ -68.74664307]]\n",
      "step: 5000 cost: 18379.7 \n",
      "predicted y:\n",
      " [[ 25.40249443]\n",
      " [ 43.85400391]\n",
      " [ 36.01847076]\n",
      " [ 42.14390564]\n",
      " [ 34.54243469]]\n",
      "step: 10000 cost: 197.727 \n",
      "predicted y:\n",
      " [[ 133.64881897]\n",
      " [ 173.83914185]\n",
      " [ 164.11549377]\n",
      " [ 181.58486938]\n",
      " [ 133.80302429]]\n",
      "step: 15000 cost: 5.65246 \n",
      "predicted y:\n",
      " [[ 147.61254883]\n",
      " [ 187.03881836]\n",
      " [ 178.96209717]\n",
      " [ 197.39855957]\n",
      " [ 143.35002136]]\n",
      "step: 20000 cost: 0.99821 \n",
      "predicted y:\n",
      " [[ 150.4889679 ]\n",
      " [ 185.18148804]\n",
      " [ 179.86529541]\n",
      " [ 197.54165649]\n",
      " [ 141.47080994]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        cost_val, hypo_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%5000 == 0:\n",
    "            print(\"step:\", step, \"cost:\", cost_val, \"\\npredicted y:\\n\", hypo_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adadelta는 gradient를 누적시키는 optimizer이다.\n",
    "\n",
    "그러므로 과거의 data가 현재의 data에 영향을 준다는 것을 전제하고 있으므로 과거 data와 현재 data가 아무 관계가 없는 선형 모델에서 그렇게 좋지 않은 결과가 나온 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(1e-5, 0.5)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 optimizer와 달리 momentum은 learing rate말고도 momentum이라는 것을 설정해 줘야 한다. (위의 예시에서는 두 번째 parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 68860.0 \n",
      "predicting y:\n",
      " [[ -87.23231506]\n",
      " [ -91.4056015 ]\n",
      " [ -97.27399445]\n",
      " [-102.95302582]\n",
      " [ -68.74664307]]\n",
      "step: 5000 cost: 1.44058 \n",
      "predicting y:\n",
      " [[ 150.24179077]\n",
      " [ 185.29051208]\n",
      " [ 179.94981384]\n",
      " [ 197.78691101]\n",
      " [ 141.08807373]]\n",
      "step: 10000 cost: 0.916466 \n",
      "predicting y:\n",
      " [[ 150.74916077]\n",
      " [ 184.99040222]\n",
      " [ 180.16584778]\n",
      " [ 197.47181702]\n",
      " [ 141.09231567]]\n",
      "step: 15000 cost: 0.622517 \n",
      "predicting y:\n",
      " [[ 150.93809509]\n",
      " [ 184.89830017]\n",
      " [ 180.27120972]\n",
      " [ 197.17822266]\n",
      " [ 141.28387451]]\n",
      "step: 20000 cost: 0.441686 \n",
      "predicting y:\n",
      " [[ 151.07244873]\n",
      " [ 184.83554077]\n",
      " [ 180.3495636 ]\n",
      " [ 196.94480896]\n",
      " [ 141.44667053]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        cost_val, hypo_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%5000 == 0:\n",
    "            print(\"step:\", step, \"cost:\", cost_val, \"\\npredicting y:\\n\", hypo_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(1e-3)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 68860.0 \n",
      "predicted y:\n",
      " [[ -87.23231506]\n",
      " [ -91.4056015 ]\n",
      " [ -97.27399445]\n",
      " [-102.95302582]\n",
      " [ -68.74664307]]\n",
      "step: 5000 cost: 0.577169 \n",
      "predicted y:\n",
      " [[ 150.92687988]\n",
      " [ 184.69987488]\n",
      " [ 179.82000732]\n",
      " [ 197.12867737]\n",
      " [ 141.41873169]]\n",
      "step: 10000 cost: 0.198688 \n",
      "predicted y:\n",
      " [[ 151.41647339]\n",
      " [ 184.44650269]\n",
      " [ 179.90222168]\n",
      " [ 196.57073975]\n",
      " [ 141.89382935]]\n",
      "step: 15000 cost: 0.142456 \n",
      "predicted y:\n",
      " [[ 151.58512878]\n",
      " [ 184.36265564]\n",
      " [ 179.93363953]\n",
      " [ 196.3480072 ]\n",
      " [ 142.09187317]]\n",
      "step: 20000 cost: 0.133451 \n",
      "predicted y:\n",
      " [[ 151.64553833]\n",
      " [ 184.33312988]\n",
      " [ 179.95223999]\n",
      " [ 196.26086426]\n",
      " [ 142.16299438]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        cost_val, hypo_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%5000 == 0:\n",
    "            print(\"step:\", step, \"cost:\", cost_val, \"\\npredicted y:\\n\", hypo_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam 다음으로 성적이 제일 좋다.\n",
    "\n",
    "Adadelta와 비슷하지만 훨씬 잘 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(1.5)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 68860.0 \n",
      "predicted y:\n",
      " [[ -87.23231506]\n",
      " [ -91.4056015 ]\n",
      " [ -97.27399445]\n",
      " [-102.95302582]\n",
      " [ -68.74664307]]\n",
      "step: 5000 cost: 0.586276 \n",
      "predicted y:\n",
      " [[ 150.99961853]\n",
      " [ 184.86265564]\n",
      " [ 179.92234802]\n",
      " [ 197.3021698 ]\n",
      " [ 141.54165649]]\n",
      "step: 10000 cost: 0.238315 \n",
      "predicted y:\n",
      " [[ 151.44346619]\n",
      " [ 184.62606812]\n",
      " [ 179.99736023]\n",
      " [ 196.8553772 ]\n",
      " [ 141.89830017]]\n",
      "step: 15000 cost: 0.150578 \n",
      "predicted y:\n",
      " [[ 151.62657166]\n",
      " [ 184.53460693]\n",
      " [ 180.02790833]\n",
      " [ 196.61959839]\n",
      " [ 142.11032104]]\n",
      "step: 20000 cost: 0.127507 \n",
      "predicted y:\n",
      " [[ 151.71615601]\n",
      " [ 184.49026489]\n",
      " [ 180.04751587]\n",
      " [ 196.49842834]\n",
      " [ 142.21551514]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        cost_val, hypo_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step%5000 == 0:\n",
    "            print(\"step:\", step, \"cost:\", cost_val, \"\\npredicted y:\\n\", hypo_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 모델에 적합한 특징답게, 선형 모델에서 우수한 성적이 나온다.\n",
    "\n",
    "거의 Adam과 비슷하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 가지 주의점은 optimizer별로 잘 되는 learing rate가 다르니 0.1씩이나 0.05씩 값을 조정해나가면서 찾는 게 좋은 것 같다.\n",
    "\n",
    "초기 값이 뭐냐에 따라 써야하는 lr이 다른 것 같기도 하다. \n",
    "\n",
    "시작점이 어디냐에 따라서 모델이 local minmum이라는 함정에 빠질수도 그렇지 않을 수도 있기 때문이다...!\n",
    "\n",
    "왠만하면 Adam을 쓰도록 하자...!\n",
    "\n",
    "하지만 sparse data하고 과거의 데이터가 현재에도 영향을 미칠 때(자연어, 스피치, finance 등등) Adadelta도 시도해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
